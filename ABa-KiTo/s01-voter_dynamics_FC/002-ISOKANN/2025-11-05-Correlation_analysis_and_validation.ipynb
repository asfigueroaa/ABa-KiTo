{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419cc13a",
   "metadata": {},
   "source": [
    "# Correlation analysis\n",
    "Date: 27.10.2025\n",
    "\n",
    "In this notebook I do the correlation analyisis to look for what internal variable correlates the best with the chi-values.\n",
    "\n",
    "Steps:\n",
    "1. Normalize the data\n",
    "2. Compute Spearman, Mutual Information, and Random Forest Importance\n",
    "3. Analyze micro and macro variables\n",
    "4. Produce comparision charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141c1c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194c4829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_mi(x, y, gridsize=100, bw_method=None):\n",
    "    \"\"\"\n",
    "    KDE-based mutual information matching ISOKANN.jl implementation\n",
    "    \"\"\"\n",
    "    # Create grid\n",
    "    xg = np.linspace(x.min(), x.max(), gridsize)\n",
    "    yg = np.linspace(y.min(), y.max(), gridsize)\n",
    "    dx = xg[1] - xg[0]\n",
    "    dy = yg[1] - yg[0]\n",
    "    \n",
    "    # Estimate joint density\n",
    "    xy = np.vstack([x, y])\n",
    "    kde_joint = gaussian_kde(xy, bw_method=bw_method)\n",
    "    xg_mesh, yg_mesh = np.meshgrid(xg, yg)\n",
    "    positions = np.vstack([xg_mesh.ravel(), yg_mesh.ravel()])\n",
    "    pxy = kde_joint(positions).reshape(gridsize, gridsize).T\n",
    "    \n",
    "    # Estimate marginals\n",
    "    px = np.sum(pxy, axis=1, keepdims=True) * dy\n",
    "    py = np.sum(pxy, axis=0, keepdims=True) * dx\n",
    "    \n",
    "    # Compute MI (avoid log(0))\n",
    "    px_py = px @ py\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        integrand = pxy * np.log(pxy / px_py)\n",
    "        integrand[~np.isfinite(integrand)] = 0\n",
    "    \n",
    "    return np.sum(integrand) * dx * dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c73aae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "#1 Load data\n",
    "# Get the absolute path of the parent directory (project root)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\",'..'))\n",
    "\n",
    "# Add it to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "#Load data formatted for ISOKANN.jl from ABM simulations\n",
    "# Create the path and ensure the directory exists for saving the data\n",
    "data_path = os.path.join('data', 'processed', 'isokann', '001_results')\n",
    "data_dir =  os.path.join(project_root, data_path,'')\n",
    "# Read data\n",
    "states_data = np.load(data_dir + '20225-11-05-Simulation_data_for_validation.npz')\n",
    "xs = states_data['xs'] #xs.shape (n_dim, n_samples)\n",
    "\n",
    "# # # --- Load chi function ---\n",
    "chivals_path = os.path.join('data', 'processed', 'isokann', '001_results', 'chi_vals', '')\n",
    "chivals_dir = os.path.join(project_root, chivals_path)\n",
    "chi = np.load(data_dir + '/chi_vals/chi_values_rand_init_capitals.npz')\n",
    "\n",
    "print(\"data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86f1e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Normalize the microvariables\n",
    "n_micro = 200\n",
    "n_macro = 12\n",
    "\n",
    "xs_micro = xs[:n_micro,:]\n",
    "xs_macro = xs[-n_macro:, :]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xs_micro_scaled = scaler.fit_transform(xs_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Normalize the microvariables\n",
    "n_micro = 200\n",
    "n_macro = 12\n",
    "\n",
    "xs_micro = xs[:n_micro,:]\n",
    "xs_macro = xs[-n_macro:, :]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "xs_micro_scaled = scaler.fit_transform(xs_micro)\n",
    "\n",
    "\n",
    "# Combine micro + macro into single DataFrame for analysis\n",
    "all_features = np.vstack((xs_micro_scaled, xs_macro))\n",
    "#ll_features = xs\n",
    "#labels = [f\"agent_{i}\" for i in range(n_micro)] + [f\"macro_{i}\" for i in range(n_macro)]\n",
    "labels = []\n",
    "for i in range(100):\n",
    "    n = i \n",
    "    labels.append(f\"agent_{i} PB\")\n",
    "    labels.append(f\"agent_{i} PG\")\n",
    "\n",
    "labels += [f\"macro_{i}\" for i in range(n_macro)]\n",
    "\n",
    "df = pd.DataFrame(all_features.T, columns=labels)\n",
    "df[\"chi\"] = chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72212eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['agent_0 PB', 'agent_0 PG', 'agent_1 PB', 'agent_1 PG', 'agent_2 PB',\n",
       "       'agent_2 PG', 'agent_3 PB', 'agent_3 PG', 'agent_4 PB', 'agent_4 PG',\n",
       "       ...\n",
       "       'macro_3', 'macro_4', 'macro_5', 'macro_6', 'macro_7', 'macro_8',\n",
       "       'macro_9', 'macro_10', 'macro_11', 'chi'],\n",
       "      dtype='object', length=213)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c9acdbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Spearman correlations...\n",
      "Computing Mutual Information...\n",
      "\n",
      "Computing KDE-based Mutual Information...\n",
      "\n",
      "Top 10 χ-correlated variables:\n",
      "        variable  spearman  mutual_info    mi_kde  abs_spearman\n",
      "211     macro_11  0.763439     0.540429  0.469620      0.763439\n",
      "208      macro_8 -0.763439     0.540362  0.469620      0.763439\n",
      "209      macro_9  0.678735     0.414105  0.394057      0.678735\n",
      "79   agent_39 PG  0.671946     0.424694  0.344978      0.671946\n",
      "197  agent_98 PG  0.671078     0.424295  0.344772      0.671078\n",
      "195  agent_97 PG  0.670927     0.423278  0.344799      0.670927\n",
      "43   agent_21 PG  0.669838     0.419656  0.340368      0.669838\n",
      "173  agent_86 PG  0.669766     0.422844  0.341790      0.669766\n",
      "165  agent_82 PG  0.669727     0.421471  0.345656      0.669727\n",
      "181  agent_90 PG  0.669105     0.421418  0.342945      0.669105\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# === 1. Spearman Correlation =========================\n",
    "# =====================================================\n",
    "print(\"Computing Spearman correlations...\")\n",
    "spearman_corr = []\n",
    "for var in labels:\n",
    "    rho, _ = spearmanr(df[var], df[\"chi\"])\n",
    "    spearman_corr.append(rho)\n",
    "\n",
    "# =====================================================\n",
    "# === 2. Mutual Information ===========================\n",
    "# =====================================================\n",
    "print(\"Computing Mutual Information...\")\n",
    "mi = mutual_info_regression(df[labels], df[\"chi\"], random_state=42)\n",
    "\n",
    "# =====================================================\n",
    "# === 3.  KDE-based Mutual Information  ===============\n",
    "# =====================================================\n",
    "print(\"\\nComputing KDE-based Mutual Information...\")\n",
    "feature_columns = [col for col in df.columns if col != \"chi\"]\n",
    "mi_kde = [kde_mi(df[\"chi\"].values, df[col].values) for col in feature_columns]\n",
    "\n",
    "\n",
    "# # =====================================================\n",
    "# # === 3. Random Forest Feature Importance =============\n",
    "# # =====================================================\n",
    "# print(\"Training Random Forest for feature importance...\")\n",
    "# rf = RandomForestRegressor(\n",
    "#     n_estimators=100,\n",
    "#     max_depth=10,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# rf.fit(df[labels], df[\"chi\"])\n",
    "# rf_importance = rf.feature_importances_\n",
    "\n",
    "# =====================================================\n",
    "# === 4. Summarize Results ============================\n",
    "# =====================================================\n",
    "results = pd.DataFrame({\n",
    "    \"variable\": labels,\n",
    "    \"spearman\": spearman_corr,\n",
    "    \"mutual_info\": mi,\n",
    "    \"mi_kde\": mi_kde\n",
    "})\n",
    "\n",
    "results[\"abs_spearman\"] = results[\"spearman\"].abs()\n",
    "results.sort_values(\"abs_spearman\", ascending=False, inplace=True)\n",
    "\n",
    "# Print top 10\n",
    "print(\"\\nTop 10 χ-correlated variables:\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d17e1c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "variable & spearman & mi_kde_clipped \\\\\n",
      "macro_11 & 0.763 & 0.470 \\\\\n",
      "macro_8 & -0.763 & 0.470 \\\\\n",
      "macro_9 & 0.679 & 0.394 \\\\\n",
      "macro_10 & 0.632 & 0.352 \\\\\n",
      "macro_6 & 0.136 & 0.000 \\\\\n",
      "macro_0 & 0.128 & 0.000 \\\\\n",
      "macro_4 & 0.111 & 0.000 \\\\\n",
      "macro_2 & 0.073 & 0.000 \\\\\n",
      "macro_1 & 0.068 & 0.000 \\\\\n",
      "macro_5 & 0.059 & 0.000 \\\\\n",
      "macro_3 & 0.054 & 0.000 \\\\\n",
      "macro_7 & 0.053 & 0.000 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results[\"mi_kde_clipped\"] = results[\"mi_kde\"].clip(lower=0)\n",
    "\n",
    "macro_vars = results[results[\"variable\"].str.contains(\"macro\")]\n",
    "\n",
    "\n",
    "print(macro_vars[['variable', 'spearman', 'mi_kde_clipped']].style.format(precision=3).hide(axis='index').to_latex()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Save results so analysis don#t have to be done everytime\n",
    "# results.to_csv('results_correlation_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc90dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read results\n",
    "# results_kde = pd.read_csv('results_kde.csv')\n",
    "# results_kde.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
